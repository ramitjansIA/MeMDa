{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Logo al 25% -->\n",
        "<td width=\"45%\" align=\"left\" valign=\"middle\">\n",
        "  <img src=\"https://www.upc.edu/comunicacio/ca/identitat/descarrega-arxius-grafics/fitxers-marca-principal/upc-positiu-p3005.png\" width=\"300\">\n",
        "</td>\n",
        "\n",
        "<!-- Texto al 75%, alineado a la derecha -->\n",
        "<td width=\"5%\" align=\"right\" valign=\"middle\">\n",
        "  <p style=\"margin: 0;\"><b>Intelligence Data Science and Artificial Intelligence (IDEAI)</b></p>\n",
        "  <p style=\"margin: 0;\"><b>Grau en Estad√≠stica (UB - UPC)</b></p>\n",
        "  <p style=\"margin: 0;\">M√®todes Estad√≠stics per la Mineria de Dades (MeMDa)</p>\n",
        "</td>\n",
        "\n",
        "# üß† **Transfer Learning: Aplicar estilo a las imagenes**"
      ],
      "metadata": {
        "id": "r5Mq78K2WwiT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### üîß 1. Instalaci√≥n"
      ],
      "metadata": {
        "id": "Upb-ICLDPwOg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O45eGlXBPsdt"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers==0.32.0 transformers accelerate safetensors torch torchvision --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† 2. Cargar modelos por estilo (img2img)\n",
        "\n",
        "Usamos `AutoPipelineForImage2Image` y un diccionario por estilo:"
      ],
      "metadata": {
        "id": "jXxcVwoWP17h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import AutoPipelineForImage2Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Usando dispositivo:\", device)\n",
        "\n",
        "STYLE_MODELS = {\n",
        "    \"pixar\": {\n",
        "        \"model_id\": \"nitrosocke/mo-di-diffusion\",\n",
        "        \"extra_prompt\": \"modern disney style, 3d animated movie still\"\n",
        "    },\n",
        "    \"simpsons\": {\n",
        "        \"model_id\": \"Norod78/sd-simpsons-model\",\n",
        "        \"extra_prompt\": \"simpsons style, yellow skin, flat colors, cartoon lineart, tv show screenshot\"\n",
        "    },\n",
        "    \"anime\": {\n",
        "        \"model_id\": \"gsdf/Counterfeit-V2.5\",\n",
        "        \"extra_prompt\": \"anime style, detailed eyes, cel shading\"\n",
        "    },\n",
        "    \"funko\": {\n",
        "        \"model_id\": \"runwayml/stable-diffusion-v1-5\",\n",
        "        \"extra_prompt\": \"Funko Pop figure, big head, small body, 3d vinyl toy\"\n",
        "    },\n",
        "}\n",
        "\n",
        "# Cach√© de pipelines para no descargar varias veces\n",
        "PIPELINES_CACHE = {}\n",
        "\n",
        "def get_pipeline_for_style(style: str):\n",
        "    if style not in STYLE_MODELS:\n",
        "        raise ValueError(f\"Estilo '{style}' no soportado. Usa uno de: {list(STYLE_MODELS.keys())}\")\n",
        "\n",
        "    if style in PIPELINES_CACHE:\n",
        "        return PIPELINES_CACHE[style]\n",
        "\n",
        "    model_id = STYLE_MODELS[style][\"model_id\"]\n",
        "    print(f\"Cargando modelo para estilo '{style}': {model_id}\")\n",
        "\n",
        "    pipe = AutoPipelineForImage2Image.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
        "        safety_checker=None\n",
        "    ).to(device)\n",
        "\n",
        "    PIPELINES_CACHE[style] = pipe\n",
        "    return pipe\n"
      ],
      "metadata": {
        "id": "wM1hu77lP1Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si alguno de estos modelos te pide aceptar la licencia de Stable Diffusion en Hugging Face, tendr√°s que haberlo aceptado en tu cuenta y (si hace falta) usar un token en Colab.\n",
        "\n",
        "**Modelo base vs. modelo afinado**\n",
        "\n",
        "* El Stable Diffusion ‚Äúnormal‚Äù sabe dibujar un poco de todo, pero no domina 100% un estilo concreto (Simpsons, Pixar...)\n",
        "\n",
        "* Cuando quieres un estilo muy concreto, es mejor usar un **modelo ya entrenado espec√≠ficamente** con im√°genes de esa serie/estudio (por eso usamos `mo-di-diffusion` para estilo Disney/Pixar, `sd_asim_simpsons` para Simpsons, etc.).\n",
        "\n"
      ],
      "metadata": {
        "id": "OvepiweuP_xf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üñºÔ∏è 3. Subir la foto de la persona"
      ],
      "metadata": {
        "id": "_inAGZtfQAl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "\n",
        "uploaded = files.upload()  # elige una foto de una persona\n",
        "\n",
        "image_name = list(uploaded.keys())[0]\n",
        "init_image = Image.open(image_name).convert(\"RGB\")\n",
        "\n",
        "# Redimensionamos a algo razonable (muchos modelos est√°n entrenados a 512x512)\n",
        "init_image = init_image.resize((512, 512))\n",
        "display(init_image)"
      ],
      "metadata": {
        "id": "MztOF3uqQEE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üé® 4. Funci√≥n gen√©rica de estilizado"
      ],
      "metadata": {
        "id": "ULjOmoIpQFIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "NEGATIVE_PROMPT_COMMON = (\n",
        "    \"blurry, low quality, deformed, bad anatomy, extra limbs, distorted face, artifacts, grainy, ugly\"\n",
        ")\n",
        "\n",
        "def stylize_person(\n",
        "    init_image: Image.Image,\n",
        "    style: str,\n",
        "    strength: float = 0.65,\n",
        "    guidance_scale: float = 7.5,\n",
        "    seed: int | None = None,\n",
        "    num_inference_steps: int = 30,\n",
        "    extra_text: str = \"\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Aplica un estilo cartoon a la foto de una persona usando diferentes modelos por estilo.\n",
        "    - strength ~0.4-0.6  -> respeta bastante la cara\n",
        "    - strength ~0.7-0.9  -> cambia mucho (muy cartoon)\n",
        "    \"\"\"\n",
        "    pipe = get_pipeline_for_style(style)\n",
        "    style_info = STYLE_MODELS[style]\n",
        "\n",
        "    if seed is None:\n",
        "        seed = random.randint(0, 10_000)\n",
        "\n",
        "    generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "    base_prompt = (\n",
        "        \"portrait of the same person, centered, looking at the camera, \"\n",
        "        \"clear facial features, high quality\"\n",
        "    )\n",
        "\n",
        "    full_prompt = base_prompt + \", \" + style_info[\"extra_prompt\"]\n",
        "    if extra_text:\n",
        "        full_prompt += \", \" + extra_text\n",
        "\n",
        "    print(\"Prompt usado:\\n\", full_prompt)\n",
        "\n",
        "    image = pipe(\n",
        "        prompt=full_prompt,\n",
        "        image=init_image,\n",
        "        strength=strength,\n",
        "        guidance_scale=guidance_scale,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        negative_prompt=NEGATIVE_PROMPT_COMMON,\n",
        "        generator=generator,\n",
        "    ).images[0]\n",
        "\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "xuF3e_1IQIxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ñ∂Ô∏è 5. Probar estilos concretos\n",
        "\n",
        "Aqu√≠ puedes ir cambiando el estilo y par√°metros hasta que veas algo claramente cartoon.\n",
        "\n",
        "* **Par√°metro** `strength`\n",
        "  * Si es muy bajo (~0.3-0.4): casi no cambia la imagen -> parece \"no hace nada\"\n",
        "  * Si es medio (~0.5-0.7): se nota el estilo pero mantiene bastante la cara.\n",
        "  * Si es alto (~0.8-0.9): se vuelve muy cartoon, pero puede perder la identidad\n",
        "\n",
        "* **Par√°metro** `guidance_scale`:\n",
        "  * Valores altos (7-9) = el modelo obedece mucho al prompt (m√°s estilo)\n",
        "  * Valores bajos (4-6) = mezcla m√°s con la foto original, menos dram√°tico.\n",
        "\n",
        "* **Par√°metro** `num_inference_steps`:\n",
        "  "
      ],
      "metadata": {
        "id": "mhq9DroyQLAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo 1: ‚ÄúPixar / Disney‚Äù"
      ],
      "metadata": {
        "id": "PdDYS6qSQRwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "\n",
        "out_pixar = stylize_person(\n",
        "    init_image,\n",
        "    style=\"pixar\",\n",
        "    strength=0.7,        # m√°s alto para que se note el 3D cartoon\n",
        "    guidance_scale=8.5,  # m√°s fuerte el prompt\n",
        "    seed=1234,\n",
        ")\n",
        "display(out_pixar)\n",
        "out_pixar.save(\"persona_pixar.png\")"
      ],
      "metadata": {
        "id": "dBqqQgljQL1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo 2: ‚ÄúSimpsons‚Äù"
      ],
      "metadata": {
        "id": "ndv4CzZAQW9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_simpsons = stylize_person(\n",
        "    init_image,\n",
        "    style=\"simpsons\",\n",
        "    strength=0.75,       # Simpsons necesita bastante deformaci√≥n\n",
        "    guidance_scale=8.5,\n",
        "    seed=1234,\n",
        ")\n",
        "display(out_simpsons)\n",
        "out_simpsons.save(\"persona_simpsons.png\")"
      ],
      "metadata": {
        "id": "c-jIvP8PQWZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo 3: ‚ÄúAnime‚Äù"
      ],
      "metadata": {
        "id": "DHK2HbFFQbws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_anime = stylize_person(\n",
        "    init_image,\n",
        "    style=\"anime\",\n",
        "    strength=0.65,\n",
        "    guidance_scale=8.0,\n",
        "    seed=1234,\n",
        ")\n",
        "display(out_anime)\n",
        "out_anime.save(\"persona_anime.png\")"
      ],
      "metadata": {
        "id": "OowtXaXiQeIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejemplo 4: ‚ÄúFunko‚Äù"
      ],
      "metadata": {
        "id": "e_wW5kbmQgBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_funko = stylize_person(\n",
        "    init_image,\n",
        "    style=\"funko\",\n",
        "    strength=0.7,\n",
        "    guidance_scale=8.0,\n",
        "    seed=1234,\n",
        ")\n",
        "display(out_funko)\n",
        "out_funko.save(\"persona_funko.png\")\n"
      ],
      "metadata": {
        "id": "ha1WbSuKQfu4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}