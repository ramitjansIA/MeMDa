{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Logo al 25% -->\n",
        "<td width=\"45%\" align=\"left\" valign=\"middle\">\n",
        "  <img src=\"https://www.upc.edu/comunicacio/ca/identitat/descarrega-arxius-grafics/fitxers-marca-principal/upc-positiu-p3005.png\" width=\"300\">\n",
        "</td>\n",
        "\n",
        "<!-- Texto al 75%, alineado a la derecha -->\n",
        "<td width=\"5%\" align=\"right\" valign=\"middle\">\n",
        "  <p style=\"margin: 0;\"><b>Intelligence Data Science and Artificial Intelligence (IDEAI)</b></p>\n",
        "  <p style=\"margin: 0;\"><b>Grau en Estad√≠stica (UB - UPC)</b></p>\n",
        "  <p style=\"margin: 0;\">M√®todes Estad√≠stics per la Mineria de Dades (MeMDa)</p>\n",
        "</td>\n",
        "\n",
        "# üß† **Convolutional Neural Networks (CNN)**"
      ],
      "metadata": {
        "id": "JAZXZgHoS9QS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1RBIwlPnyUL"
      },
      "source": [
        "## Importar Librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:12:59.231970Z",
          "start_time": "2018-11-08T00:12:51.800950Z"
        },
        "id": "G4RqDOBTnyUL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "_8gX8FPNoODe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:13:12.550878Z",
          "start_time": "2018-11-08T00:12:59.234748Z"
        },
        "id": "ZZhYDCq6nyUL"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras import Input, Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, LeakyReLU\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a emparejar el notebook de python con el google drive"
      ],
      "metadata": {
        "id": "cgtCwDt6n6z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "93cImWsVn6Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imagenes y p√≠xeles**"
      ],
      "metadata": {
        "id": "qgZWEiodpj38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La red toma como entrada los pixeles de una imagen. Si tenemos una imagen con apenas 28√ó28 pixeles de alto y ancho, eso equivale a  784 neuronas. Y eso es si s√≥lo tenemos 1 color (escala de grises). Si tuvi√©ramos una imagen a color, necesitar√≠amos 3 canales (red, green, blue) y entonces usar√≠amos 28x28x3 = 2352 neuronas de entrada. Esa es nuestra capa de entrada.\n",
        "\n",
        "![imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-01.png)"
      ],
      "metadata": {
        "id": "SuuVXqR0pyE0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abi6ojyYnyUM"
      },
      "source": [
        "#### Cargar set de Im√°genes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dirname = os.path.join(os.getcwd(), 'drive/MyDrive/DOCENCIA/ANN/sports')\n",
        "imgpath = dirname + os.sep"
      ],
      "metadata": {
        "id": "em9XBB986OLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:45.248080Z",
          "start_time": "2018-11-08T00:13:12.553292Z"
        },
        "scrolled": true,
        "id": "EBZMAT7OnyUM"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "directories = []\n",
        "dircount = []\n",
        "prevRoot=''\n",
        "cant=0\n",
        "\n",
        "print(\"leyendo imagenes de \",imgpath)\n",
        "\n",
        "for root, dirnames, filenames in os.walk(imgpath):\n",
        "    for filename in filenames:\n",
        "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
        "            cant=cant+1\n",
        "            filepath = os.path.join(root, filename)\n",
        "            image = plt.imread(filepath)\n",
        "            images.append(image)\n",
        "            b = \"Leyendo...\" + str(cant)\n",
        "            print (b, end=\"\\r\")\n",
        "            if prevRoot !=root:\n",
        "                print(root, cant)\n",
        "                prevRoot=root\n",
        "                directories.append(root)\n",
        "                dircount.append(cant)\n",
        "                cant=0\n",
        "dircount.append(cant)\n",
        "\n",
        "dircount = dircount[1:]\n",
        "dircount[0]=dircount[0]+1\n",
        "print('Directorios leidos:',len(directories))\n",
        "print(\"Imagenes en cada directorio\", dircount)\n",
        "print('suma Total de imagenes en subdirs:',sum(dircount))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuEFuudanyUM"
      },
      "source": [
        "### Creamos las etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:45.269861Z",
          "start_time": "2018-11-08T00:16:45.251786Z"
        },
        "id": "FOpWs5h8nyUM"
      },
      "outputs": [],
      "source": [
        "labels=[]\n",
        "indice=0\n",
        "for cantidad in dircount:\n",
        "    for i in range(cantidad):\n",
        "        labels.append(indice)\n",
        "    indice=indice+1\n",
        "print(\"Cantidad etiquetas creadas: \",len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:45.285925Z",
          "start_time": "2018-11-08T00:16:45.273489Z"
        },
        "id": "CDZF3GPfnyUM"
      },
      "outputs": [],
      "source": [
        "deportes=[]\n",
        "indice=0\n",
        "for directorio in directories:\n",
        "    name = directorio.split(os.sep)\n",
        "    print(indice , name[len(name)-1])\n",
        "    deportes.append(name[len(name)-1])\n",
        "    indice=indice+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:45.498672Z",
          "start_time": "2018-11-08T00:16:45.290061Z"
        },
        "id": "gSaTFEyfnyUM"
      },
      "outputs": [],
      "source": [
        "y = np.array(labels)\n",
        "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
        "\n",
        "# Find the unique numbers from the train labels\n",
        "classes = np.unique(y)\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vMHtcYqnyUM"
      },
      "source": [
        "## Creamos Sets de Entrenamiento y Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:45.669596Z",
          "start_time": "2018-11-08T00:16:45.502716Z"
        },
        "id": "0X-yVNhsnyUM"
      },
      "outputs": [],
      "source": [
        "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.2)\n",
        "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
        "print('Testing data shape : ', test_X.shape, test_Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:49.319746Z",
          "start_time": "2018-11-08T00:16:45.673944Z"
        },
        "id": "Rvoa2FXknyUM"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[5,5])\n",
        "\n",
        "# Display the first image in training data\n",
        "plt.subplot(121)\n",
        "plt.imshow(train_X[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
        "\n",
        "# Display the first image in testing data\n",
        "plt.subplot(122)\n",
        "plt.imshow(test_X[0,:,:], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daVoKZj8nyUM"
      },
      "source": [
        "## Preprocesamos las imagenes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de alimentar la red, recuerda que como entrada nos conviene normalizar los valores. Los colores de los pixeles tienen valores que van de 0 a 255, haremos una transformaci√≥n de cada pixel: ‚Äúvalor/255‚Äù y nos quedar√° siempre un valor entre 0 y 1.\n",
        "\n",
        "![imagen2](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-02.png)"
      ],
      "metadata": {
        "id": "UK9Y-E0hrerV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:50.798162Z",
          "start_time": "2018-11-08T00:16:49.322999Z"
        },
        "id": "YLiQuAEFnyUM"
      },
      "outputs": [],
      "source": [
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "train_X = train_X / 255.\n",
        "test_X = test_X / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXdBrsuvnyUN"
      },
      "source": [
        "### Hacemos el One-hot Encoding para la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:50.815482Z",
          "start_time": "2018-11-08T00:16:50.800831Z"
        },
        "id": "_l0aIVnjnyUN"
      },
      "outputs": [],
      "source": [
        "# Change the labels from categorical to one-hot encoding\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n",
        "\n",
        "# Display the change for category label using one-hot encoding\n",
        "print('Original label:', train_Y[0])\n",
        "print('After conversion to one-hot:', train_Y_one_hot[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqwI_ZoPnyUN"
      },
      "source": [
        "## Creamos el Set de Entrenamiento y Validaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:51.218520Z",
          "start_time": "2018-11-08T00:16:50.818992Z"
        },
        "id": "qeq_ZYGonyUN"
      },
      "outputs": [],
      "source": [
        "#Mezclar todo y crear los grupos de entrenamiento y testing\n",
        "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:51.228116Z",
          "start_time": "2018-11-08T00:16:51.222460Z"
        },
        "id": "SU7p3l2dnyUN"
      },
      "outputs": [],
      "source": [
        "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0J3MEj-nyUN"
      },
      "source": [
        "## **Creamos el modelo de CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora comienza el *procesado distintivo* de las CNN. Es decir, haremos las llamadas *convoluciones*:\n",
        "\n",
        "Estas consisten en tomar *grupos de pixeles cercanos* de la imagen de entrada e ir operando matem√°ticamente (producto escalar) contra una peque√±a matriz que se llama kernel. Ese kernel supongamos de tama√±o 3√ó3 pixels ‚Äúrecorre‚Äù todas las neuronas de entrada (de izquierda-derecha, de arriba-abajo) y genera una nueva matriz de salida, que en definitiva ser√° nuestra nueva capa de neuronas ocultas. NOTA: si la imagen fuera a color, el kernel realmente ser√≠a de 3x3x3 es decir: un filtro con 3 kernels de 3√ó3; luego  esos 3 filtros se suman (y se le suma una unidad bias) y conformar√°n 1 salida (c√≥mo si fuera 1 solo canal).\n",
        "\n",
        "![images](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-03.png)"
      ],
      "metadata": {
        "id": "uJVytPGHr9qY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Filtros:**\n",
        "### Conjunto de Kernels\n",
        "\n",
        "Cuando generamos nuestra matriz agregada, en realidad, no aplicaremos 1 s√≥lo kernel, si no que tendremos muchos kernel (en su conjunto se llama filtros). Por ejemplo en esta primer convoluci√≥n podr√≠amos tener 32 filtros, con lo cual realmente obtendremos 32 matrices de salida (este conjunto se conoce como *feature mapping*), cada una de 28x28x1 dando un total del 25.088 neuronas para nuestra **PRIMER CAPA OCULTA** de neuronas.\n",
        "\n",
        "\\\n",
        "![imagenes](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn_kernel.gif)\n",
        "\n",
        "A medida que vamos desplazando el kernel y vamos obteniendo una *nueva imagen* filtrada por el *kernel*. En esta primer convoluci√≥n y siguiendo con el ejemplo anterior, es como si obtuvi√©ramos 32 *im√°genes filtradas nuevas*. Estas im√°genes nuevas lo que est√°n ‚Äúdibujando‚Äù son ciertas caracter√≠sticas de la imagen original. Esto ayudar√° en el futuro a poder distinguir un objeto de otro.\n",
        "\n",
        "![imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/CNN-04.png)\n",
        "\n",
        "## **La funci√≥n de activaci√≥n**\n",
        "\n",
        "La funci√≥n de activaci√≥n m√°s utilizada para este tipo de redes neuronales es la llamada **ReLu** por *Rectifier Linear Unit* y consiste en f(x) = max(0,x).\n",
        "\n",
        "## **Subsampling**\n",
        "\n",
        "Ahora viene un paso en el que reduciremos la cantidad de neuronas antes de hacer una nueva convoluci√≥n. Estp es debido porque a partir de nuestra imagen blanco y negro de 28x28px tenemos una primer capa de entrada de 784 neuronas y luego de la primer convoluci√≥n obtenemos una capa oculta de 25.088 neuronas -que realmente son nuestros 32 mapas de caracter√≠sticas de 28√ó28-\n",
        "\n",
        "Si hici√©ramos una nueva convoluci√≥n a partir de esta capa, el n√∫mero de neuronas de la pr√≥xima capa se ir√≠a por las nubes (y ello implica mayor procesamiento)! Para reducir el tama√±o de la pr√≥xima capa de neuronas haremos un proceso de subsampling en el que reduciremos el tama√±o de nuestras im√°genes filtradas pero en donde deber√°n prevalecer las caracter√≠sticas m√°s importantes que detect√≥ cada filtro. Hay diversos tipos de subsampling, a continuaci√≥n veremos el **m√°s usado**: *Max-Pooling*\n",
        "\n",
        "## **Max-Pooling**\n",
        "\n",
        "Vamos a intentar explicarlo con un ejemplo: supongamos que haremos *Max-pooling* de tama√±o 2√ó2. Esto quiere decir que recorreremos cada una de nuestras 32 im√°genes de caracter√≠sticas obtenidas anteriormente de 28x28px de izquierda-derecha, arriba-abajo PERO en vez de tomar de a 1 pixel, tomaremos de ‚Äú2√ó2‚Äù (2 de alto por 2 de ancho = 4 pixeles) e iremos preservando el valor ‚Äúm√°s alto‚Äù de entre esos 4 pixeles (por eso lo de ‚ÄúMax‚Äù). En este caso, usando 2√ó2, la imagen resultante es reducida ‚Äúa la mitad‚Äùy quedar√° de 14√ó14 pixeles. Luego de este proceso de subsamplig nos quedar√°n  32 im√°genes de 14√ó14, pasando de haber tenido 25.088 neuronas a  6.272, son bastantes menos y -en teor√≠a- siguen almacenando la informaci√≥n m√°s importante para detectar caracter√≠sticas deseadas.\n",
        "\n",
        "![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-05.png)\n",
        "\n",
        "Muy bien, pues esa ha sido una primer convoluci√≥n: consiste de una entrada, un conjunto de filtros, generamos un mapa de caracter√≠sticas y hacemos un subsampling. Con lo cual, en el ejemplo de im√°genes de 1 s√≥lo color tendremos:\n",
        "\n",
        "![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-06.png)\n",
        "\n",
        "\n",
        "La **primer convoluci√≥n** es capaz de detectar caracter√≠sticas primitivas como lineas √≥ curvas. A medida que hagamos m√°s capas con las convoluciones, los mapas de caracter√≠sticas ser√°n capaces de reconocer formas m√°s complejas, y el conjunto total de capas de convoluciones podr√° *ver*.\n",
        "\n",
        "Pues ahora deberemos hacer una Segunda convoluci√≥n que ser√°:\n",
        "\n",
        "![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-07.png)\n",
        "\n",
        "La **3er convoluci√≥n** comenzar√° en tama√±o 7√ó7 pixels y luego del *max-pooling* quedar√° en 3√ó3 con lo cual podr√≠amos hacer s√≥lo 1 convoluci√≥n m√°s. En este ejemplo empezamos con una imagen de 28x28px e hicimos 3 convoluciones. Si la imagen inicial hubiese sido mayor (de 224x224px) a√∫n hubi√©ramos podido seguir haciendo convoluciones.\n",
        "\n",
        "Llegamos a la √∫ltima convoluci√≥n y nos queda el desenlace‚Ä¶\n",
        "\n",
        "Para terminar, tomaremos la √∫ltima capa oculta a la que hicimos *subsampling*, que se dice que es *tridimensional* por tomar la forma -en nuestro ejemplo- 3x3x128 (alto,ancho,mapas) y la *aplanamos*, esto es que deja de ser tridimensional, y pasa a ser una capa de neuronas *tradicionales*, de las que ya conoc√≠amos. Por ejemplo, podr√≠amos aplanar (y conectar) a una nueva capa oculta de 100 neuronas feedforward.\n",
        "\n",
        "![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/CNN-08.png)\n",
        "\n",
        "Entonces, a esta nueva capa oculta *tradicional*, le aplicamos una funci√≥n llamada **Softmax** que conecta contra la capa de salida final que tendr√° la cantidad de neuronas correspondientes con las clases que estamos clasificando. Si clasificamos perros y gatos, ser√°n 2 neuronas. Si es el dataset Mnist num√©rico ser√°n 10 neuronas de salida. Si clasificamos coches, aviones √≥ barcos ser√°n 3, etc.\n",
        "\n",
        "Las salidas al momento del entrenamiento tendr√°n el formato conocido como **one-hot-encoding** en el que para perros y gatos sera: [1,0] y [0,1], para coches, aviones √≥ barcos ser√° [1,0,0]; [0,1,0];[0,0,1].\n",
        "\n",
        "Y la funci√≥n de *Softmax* se encarga de pasar a probabilidad (entre 0 y 1) a las neuronas de salida. Por ejemplo una salida [0,2 0,8] nos indica 20% probabilidades de que sea perro y 80% de que sea gato.\n",
        "\n",
        "### **Backpropagation**\n",
        "\n",
        "El proceso es similar al de las redes tradicionales en las que tenemos una entrada y una salida esperada (por eso aprendizaje supervisado) y mediante el *backpropagation* mejoramos el valor de los pesos de las interconexiones entre capas de neuronas y a medida que iteramos esos pesos se ajustan hasta ser √≥ptimos.\n",
        "\n",
        "En el caso de la CNN, deberemos ajustar el valor de los pesos de los distintos kernels. Esto es una gran ventaja al momento del aprendizaje pues como vimos cada kernel es de un tama√±o reducido, en nuestro ejemplo en la primer convoluci√≥n es de tama√±o de 3√ó3, eso son s√≥lo 9 par√°metros que debemos ajustar en 32 filtros dan un total de 288 par√°metros. En comparaci√≥n con los pesos entre dos capas de neuronas ‚Äútradicionales‚Äù: una de 748 y otra de 6272 en donde est√°n TODAS interconectarlas con TODAS y eso equivaldr√≠a a tener que entrenar y ajustar m√°s de 4,5 millones de pesos (repito: s√≥lo para 1 capa)."
      ],
      "metadata": {
        "id": "JFSDiuH_yPA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Arquitectura b√°sica**"
      ],
      "metadata": {
        "id": "PCMiWrh6HaPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumiendo: podemos decir que los elementos que usamos para crear CNNs son:\n",
        "\n",
        "- **Entrada:** Ser√°n los pixeles de la imagen. Ser√°n alto, ancho y profundidad ser√° 1 s√≥lo color o 3 para Red,Green,Blue.\n",
        "\n",
        "- **Capa De Convoluci√≥n:** procesar√° la salida de neuronas que est√°n conectadas en ‚Äúregiones locales‚Äù de entrada (es decir pixeles cercanos), calculando el producto escalar entre sus pesos (valor de pixel) y una peque√±a regi√≥n a la que est√°n conectados en el volumen de entrada. Aqu√≠ usaremos por ejemplo 32 filtros o la cantidad que decidamos y ese ser√° el volumen de salida.\n",
        "\n",
        "- **‚ÄúCAPA RELU‚Äù** aplicar√° la funci√≥n de activaci√≥n en los elementos de la matriz.\n",
        "\n",
        "- **POOL √≥ SUBSAMPLING:** Har√° una reducci√≥n en las dimensiones alto y ancho, pero se mantiene la profundidad.\n",
        "\n",
        "- **CAPA ‚ÄúTRADICIONAL‚Äù** red de neuronas feedforward que conectar√° con la √∫ltima capa de subsampling y finalizar√° con la cantidad de neuronas que queremos clasificar."
      ],
      "metadata": {
        "id": "KAWuIhEgHgnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Declaraci√≥n de par√°metros"
      ],
      "metadata": {
        "id": "57CIHipUc0v7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:51.244776Z",
          "start_time": "2018-11-08T00:16:51.238704Z"
        },
        "id": "4sYxsNCWnyUN"
      },
      "outputs": [],
      "source": [
        "#declaramos variables con los par√°metros de configuraci√≥n de la red\n",
        "INIT_LR = 1e-3 # Valor inicial de learning rate. El valor 1e-3 corresponde con 0.001\n",
        "epochs = 10 # Cantidad de iteraciones completas al conjunto de imagenes de entrenamiento\n",
        "batch_size = 64 # cantidad de im√°genes que se toman a la vez en memoria"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construcci√≥n del modelo"
      ],
      "metadata": {
        "id": "Vw4wrYMBc7VP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:51.384131Z",
          "start_time": "2018-11-08T00:16:51.252188Z"
        },
        "id": "cQU6vIn7nyUN"
      },
      "outputs": [],
      "source": [
        "sport_model = Sequential()\n",
        "sport_model.add(Input(shape = (21, 28, 3)))\n",
        "sport_model.add(Conv2D(32, kernel_size = (3, 3), activation = 'linear', padding = 'same'))\n",
        "sport_model.add(LeakyReLU(negative_slope = 0.1))\n",
        "sport_model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
        "sport_model.add(Dropout(0.5))\n",
        "sport_model.add(Flatten())\n",
        "sport_model.add(Dense(32, activation = 'linear'))\n",
        "sport_model.add(LeakyReLU(negative_slope = 0.1))\n",
        "sport_model.add(Dropout(0.5))\n",
        "sport_model.add(Dense(nClasses, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:51.401674Z",
          "start_time": "2018-11-08T00:16:51.386676Z"
        },
        "id": "75z1VesknyUN"
      },
      "outputs": [],
      "source": [
        "sport_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(sport_model, to_file='modelo_red_neuronal.png', show_shapes = True, show_layer_names = True)\n",
        "\n",
        "# Mostrar la imagen generada\n",
        "img = plt.imread('modelo_red_neuronal.png')\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Opcional: desactivar los ejes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hp_EIHVhHnlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.optimizers import Adagrad\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "\n",
        "# Define un programador de tasa de aprendizaje\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate = INIT_LR,  # Tasa de aprendizaje inicial\n",
        "    decay_steps = 100,                # N√∫mero de pasos para aplicar el decaimiento\n",
        "    decay_rate = INIT_LR / 100,       # Factor de decaimiento (0.96 es un ejemplo)\n",
        "    staircase = False                 # `False` para un decaimiento continuo\n",
        ")\n"
      ],
      "metadata": {
        "id": "LRFxbTzKMFEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:16:51.472349Z",
          "start_time": "2018-11-08T00:16:51.406817Z"
        },
        "id": "tAp8B_PgnyUN"
      },
      "outputs": [],
      "source": [
        "# Compilamos el modelo\n",
        "sport_model.compile(loss = \"categorical_crossentropy\",\n",
        "                    optimizer = Adam(learning_rate = lr_schedule),\n",
        "                    metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuz41vhUnyUN"
      },
      "source": [
        "## Entrenamos el modelo: Aprende a clasificar im√°genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:20:49.562522Z",
          "start_time": "2018-11-08T00:16:51.474807Z"
        },
        "id": "i3swtkGhnyUN"
      },
      "outputs": [],
      "source": [
        "# este paso puede tomar varios minutos, dependiendo de tu ordenador, cpu y memoria ram libre\n",
        "# como ejemplo, en mi Macbook pro tarda 4 minutos\n",
        "sport_train = sport_model.fit(train_X, train_label, batch_size = batch_size,\n",
        "                              epochs = epochs, verbose = 1,\n",
        "                              validation_data = (valid_X, valid_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:20:49.676566Z",
          "start_time": "2018-11-08T00:20:49.566203Z"
        },
        "id": "l404yeaMnyUN"
      },
      "outputs": [],
      "source": [
        "# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\n",
        "nombreFichero = \"sports_mnist.keras\"  # \"sports_mnist.h5\"\n",
        "sport_model.save(nombreFichero)\n",
        "keras.saving.save_model(sport_model, nombreFichero)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG2BQOzWnyUN"
      },
      "source": [
        "## Evaluamos la red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:20:54.462929Z",
          "start_time": "2018-11-08T00:20:49.678643Z"
        },
        "id": "CflKqy3tnyUN"
      },
      "outputs": [],
      "source": [
        "test_eval = sport_model.evaluate(test_X, test_Y_one_hot, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:20:54.474683Z",
          "start_time": "2018-11-08T00:20:54.465378Z"
        },
        "id": "iYvJw5pwnyUO"
      },
      "outputs": [],
      "source": [
        "print('Test loss:', test_eval[0])\n",
        "print('Test accuracy:', test_eval[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:20:55.014647Z",
          "start_time": "2018-11-08T00:20:54.479693Z"
        },
        "scrolled": false,
        "id": "oj-PTb1inyUO"
      },
      "outputs": [],
      "source": [
        "accuracy = sport_train.history['accuracy']\n",
        "val_accuracy = sport_train.history['val_accuracy']\n",
        "loss = sport_train.history['loss']\n",
        "val_loss = sport_train.history['val_loss']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'bo', label = 'Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label = 'Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:20:58.050602Z",
          "start_time": "2018-11-08T00:20:55.021862Z"
        },
        "id": "tno1JbDVnyUO"
      },
      "outputs": [],
      "source": [
        "predicted_classes2 = sport_model.predict(test_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:20:58.262575Z",
          "start_time": "2018-11-08T00:20:58.052878Z"
        },
        "id": "q7EG_W8_nyUO"
      },
      "outputs": [],
      "source": [
        "predicted_classes = []\n",
        "for predicted_sport in predicted_classes2:\n",
        "    predicted_classes.append(predicted_sport.tolist().index(max(predicted_sport)))\n",
        "predicted_classes = np.array(predicted_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:20:58.272559Z",
          "start_time": "2018-11-08T00:20:58.264703Z"
        },
        "id": "A79cIbUznyUO"
      },
      "outputs": [],
      "source": [
        "predicted_classes.shape, test_Y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsfsgpPBnyUO"
      },
      "source": [
        "## Aprendamos de los errores: Qu√© mejorar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:20:59.822110Z",
          "start_time": "2018-11-08T00:20:58.275464Z"
        },
        "id": "VeEIsZw0nyUO"
      },
      "outputs": [],
      "source": [
        "correct = np.where(predicted_classes == test_Y)[0]\n",
        "print(\"Found %d correct labels\" % len(correct))\n",
        "for i, correct in enumerate(correct[0:9]):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(test_X[correct].reshape(21, 28, 3), cmap = 'gray',\n",
        "               interpolation = 'none')\n",
        "    plt.title(\"predict: {}\\n real: {}\".format(deportes[predicted_classes[correct]],\n",
        "                                                    deportes[test_Y[correct]]))\n",
        "\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:21:00.942267Z",
          "start_time": "2018-11-08T00:20:59.829572Z"
        },
        "id": "gKTppx64nyUO"
      },
      "outputs": [],
      "source": [
        "incorrect = np.where(predicted_classes != test_Y)[0]\n",
        "print(\"Found %d incorrect labels\" % len(incorrect))\n",
        "for i, incorrect in enumerate(incorrect[0:9]):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(test_X[incorrect].reshape(21, 28, 3), cmap = 'gray',\n",
        "               interpolation = 'none')\n",
        "    plt.title(\"predicted: {}\\n real: {}\".format(deportes[predicted_classes[incorrect]],\n",
        "                                                    deportes[test_Y[incorrect]]))\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-11-08T00:21:00.968727Z",
          "start_time": "2018-11-08T00:21:00.947262Z"
        },
        "id": "D1pWLIh8nyUQ"
      },
      "outputs": [],
      "source": [
        "# target_names = [\"Class {}\".format(i) for i in range(nClasses)]\n",
        "target_names = [\"ciclismo\", \"f1\", \"futbol\", \"basket\", \"tenis\"]\n",
        "print(classification_report(test_Y, predicted_classes, target_names = target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5wKa0mAnyUQ"
      },
      "source": [
        "## Prediccion de una nueva imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-Sa2XI_nyUQ"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "images = []\n",
        "# AQUI ESPECIFICAMOS UNAS IMAGENES\n",
        "filenames = ['/content/drive/MyDrive/DOCENCIA/ANN/sports/testeoNew/f12_0096.jpg']\n",
        "\n",
        "for filepath in filenames:\n",
        "    image = plt.imread(filepath, 0)\n",
        "    image_resized = resize(image, (21, 28), anti_aliasing = True, clip = False,\n",
        "                           preserve_range = True)\n",
        "    images.append(image_resized)\n",
        "\n",
        "X = np.array(images, dtype = np.uint8) #convierto de lista a numpy\n",
        "test_X = X.astype('float32')\n",
        "test_X = test_X / 255.\n",
        "\n",
        "predicted_classes = sport_model.predict(test_X)\n",
        "\n",
        "for i, img_tagged in enumerate(predicted_classes):\n",
        "    print(filenames[i], deportes[img_tagged.tolist().index(max(img_tagged))])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TENSORFLOW**"
      ],
      "metadata": {
        "id": "JaNwMM5jnf6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Definir el callback de TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs\", histogram_freq=1)"
      ],
      "metadata": {
        "id": "B0t4stE7m59M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar el modelo\n",
        "sport_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Entrenar el modelo con el callback\n",
        "sport_train = sport_model.fit(train_X, train_label, epochs = 10,\n",
        "                              callbacks = [tensorboard_callback],\n",
        "                              validation_data = (valid_X, valid_label))"
      ],
      "metadata": {
        "id": "mBKbFcH4IRIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un callback de TensorBoard\n",
        "import datetime\n",
        "log_dir = \"/content/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "xnXLdMFJI4US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciar TensorBoard en Colab\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/logs/fit\n"
      ],
      "metadata": {
        "id": "p9dtmEWVJhe_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}